{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body pose estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model object from the keypointrcnn_resnet50_fpn class\n",
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# Call the eval() method to prepare the model for inference mode.\n",
    "model.eval()\n",
    " \n",
    "# Create the list of keypoints.\n",
    "keypoints = ['nose','left_eye','right_eye',\\\n",
    "'left_ear','right_ear','left_shoulder',\\\n",
    "'right_shoulder','left_elbow','right_elbow',\\\n",
    "'left_wrist','right_wrist','left_hip',\\\n",
    "'right_hip','left_knee', 'right_knee', \\\n",
    "'left_ankle','right_ankle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img1 = cv2.imread(\"../../data/running_person.jpg\")\n",
    "img2 = cv2.imread(\"../../data/standing_person.jpg\")\n",
    "img = img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the input image\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "img_tensor = transform(img)\n",
    " \n",
    "# Forward-pass the model, the input is a list, hence the output will also be a list\n",
    "output = model([img_tensor])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints_per_person(img, all_keypoints, all_scores, confs, keypoint_threshold=2, conf_threshold=0.9):\n",
    "    # initialize a set of colors from the rainbow spectrum\n",
    "    cmap = plt.get_cmap('rainbow')\n",
    "    # create a copy of the image\n",
    "    img_copy = img.copy()\n",
    "    # pick a set of N color-ids from the spectrum\n",
    "    color_id = np.arange(1,255, 255//len(all_keypoints)).tolist()[::-1]\n",
    "    # iterate for every person detected\n",
    "    for person_id in range(len(all_keypoints)):\n",
    "      # check the confidence score of the detected person\n",
    "      if confs[person_id]>conf_threshold:\n",
    "        # grab the keypoint-locations for the detected person\n",
    "        keypoints = all_keypoints[person_id, ...]\n",
    "        # grab the keypoint-scores for the keypoints\n",
    "        scores = all_scores[person_id, ...]\n",
    "        # iterate for every keypoint-score\n",
    "        for kp in range(len(scores)):\n",
    "            # check the confidence score of detected keypoint\n",
    "            if scores[kp]>keypoint_threshold:\n",
    "                # convert the keypoint float-array to a python-list of integers\n",
    "                keypoint = tuple(map(int, keypoints[kp, :2].detach().numpy().tolist()))\n",
    "                # pick the color at the specific color-id\n",
    "                color = tuple(np.asarray(cmap(color_id[person_id])[:-1])*255)\n",
    "                # draw a circle over the keypoint location\n",
    "                cv2.circle(img_copy, keypoint, 5, color, -1)\n",
    " \n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_img = draw_keypoints_per_person(img, output[\"keypoints\"], output[\"keypoints_scores\"], output[\"scores\"], keypoint_threshold=2)\n",
    "\n",
    "# Show\n",
    "plt.imshow(keypoints_img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limbs_from_keypoints(keypoints):\n",
    "  limbs = [       \n",
    "        [keypoints.index('right_eye'), keypoints.index('nose')],\n",
    "        [keypoints.index('right_eye'), keypoints.index('right_ear')],\n",
    "        [keypoints.index('left_eye'), keypoints.index('nose')],\n",
    "        [keypoints.index('left_eye'), keypoints.index('left_ear')],\n",
    "        [keypoints.index('right_shoulder'), keypoints.index('right_elbow')],\n",
    "        [keypoints.index('right_elbow'), keypoints.index('right_wrist')],\n",
    "        [keypoints.index('left_shoulder'), keypoints.index('left_elbow')],\n",
    "        [keypoints.index('left_elbow'), keypoints.index('left_wrist')],\n",
    "        [keypoints.index('right_hip'), keypoints.index('right_knee')],\n",
    "        [keypoints.index('right_knee'), keypoints.index('right_ankle')],\n",
    "        [keypoints.index('left_hip'), keypoints.index('left_knee')],\n",
    "        [keypoints.index('left_knee'), keypoints.index('left_ankle')],\n",
    "        [keypoints.index('right_shoulder'), keypoints.index('left_shoulder')],\n",
    "        [keypoints.index('right_hip'), keypoints.index('left_hip')],\n",
    "        [keypoints.index('right_shoulder'), keypoints.index('right_hip')],\n",
    "        [keypoints.index('left_shoulder'), keypoints.index('left_hip')]\n",
    "        ]\n",
    "  return limbs\n",
    " \n",
    "limbs = get_limbs_from_keypoints(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_skeleton_per_person(img, all_keypoints, all_scores, confs, keypoint_threshold=2, conf_threshold=0.9):\n",
    "     \n",
    "    # initialize a set of colors from the rainbow spectrum\n",
    "    cmap = plt.get_cmap('rainbow')\n",
    "    # create a copy of the image\n",
    "    img_copy = img.copy()\n",
    "    # check if the keypoints are detected\n",
    "    if len(output[\"keypoints\"])>0:\n",
    "      # pick a set of N color-ids from the spectrum\n",
    "      colors = np.arange(1,255, 255//len(all_keypoints)).tolist()[::-1]\n",
    "      # iterate for every person detected\n",
    "      for person_id in range(len(all_keypoints)):\n",
    "          # check the confidence score of the detected person\n",
    "          if confs[person_id]>conf_threshold:\n",
    "            # grab the keypoint-locations for the detected person\n",
    "            keypoints = all_keypoints[person_id, ...]\n",
    " \n",
    "            # iterate for every limb \n",
    "            for limb_id in range(len(limbs)):\n",
    "              # pick the start-point of the limb\n",
    "              limb_loc1 = keypoints[limbs[limb_id][0], :2].detach().numpy().astype(np.int32)\n",
    "              # pick the start-point of the limb\n",
    "              limb_loc2 = keypoints[limbs[limb_id][1], :2].detach().numpy().astype(np.int32)\n",
    "              # consider limb-confidence score as the minimum keypoint score among the two keypoint scores\n",
    "              limb_score = min(all_scores[person_id, limbs[limb_id][0]], all_scores[person_id, limbs[limb_id][1]])\n",
    "              # check if limb-score is greater than threshold\n",
    "              if limb_score> keypoint_threshold:\n",
    "                # pick the color at a specific color-id\n",
    "                color = tuple(np.asarray(cmap(colors[person_id])[:-1])*255)\n",
    "                # draw the line for the limb\n",
    "                cv2.line(img_copy, tuple(limb_loc1), tuple(limb_loc2), color, 3)\n",
    " \n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay the skeleton in the detected person\n",
    "skeletal_img = draw_skeleton_per_person(img, output[\"keypoints\"], output[\"keypoints_scores\"], output[\"scores\"],keypoint_threshold=2)\n",
    "\n",
    "# Show\n",
    "plt.imshow(skeletal_img)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
