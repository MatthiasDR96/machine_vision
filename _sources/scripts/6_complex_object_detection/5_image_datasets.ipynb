{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image datasets\n",
    "In this notebook, we will take a look at some different open source datasets. A subdivision will be made between datasets used for object detection and datasets used for image segmentation. More documentation on the used functions can be found at https://voxel51.com/ . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migrating database to v0.21.6\n"
     ]
    }
   ],
   "source": [
    "# FiftyOne is an open source toolkit for building image datasets and computer vision models.\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Images\n",
    "This dataset from Google contains approximately 9 million images annotated with image-level labels and object bounding boxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\matth\\fiftyone\\open-images-v6\\validation' if necessary\n",
      "Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to 'C:\\Users\\matth\\fiftyone\\open-images-v6\\validation\\metadata\\image_ids.csv'\n",
      "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to 'C:\\Users\\matth\\fiftyone\\open-images-v6\\validation\\metadata\\classes.csv'\n",
      "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to 'C:\\Users\\matth\\AppData\\Local\\Temp\\tmpvnqq6emj\\metadata\\hierarchy.json'\n",
      "Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv' to 'C:\\Users\\matth\\fiftyone\\open-images-v6\\validation\\labels\\detections.csv'\n",
      "Downloading 25 images\n",
      " 100% |█████████████████████| 25/25 [2.8s elapsed, 0s remaining, 13.3 files/s]      \n",
      "Dataset info written to 'C:\\Users\\matth\\fiftyone\\open-images-v6\\info.json'\n",
      "Loading 'open-images-v6' split 'validation'\n",
      " 100% |███████████████████| 25/25 [906.4ms elapsed, 0s remaining, 27.6 samples/s]      \n",
      "Dataset 'open-images-v6-validation-25' created\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Client is not connected",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# The dataset is constructed from the Open Images v6 dataset. It will contain 25 samples of images where glasses are detected.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dataset \u001b[39m=\u001b[39m foz\u001b[39m.\u001b[39mload_zoo_dataset(\n\u001b[0;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mopen-images-v6\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     max_samples \u001b[39m=\u001b[39m \u001b[39m25\u001b[39m\n\u001b[0;32m      8\u001b[0m     )\n\u001b[1;32m----> 9\u001b[0m session \u001b[39m=\u001b[39m fo\u001b[39m.\u001b[39;49mlaunch_app(dataset)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\fiftyone\\core\\session\\session.py:197\u001b[0m, in \u001b[0;36mlaunch_app\u001b[1;34m(dataset, view, spaces, color_scheme, plots, port, address, remote, desktop, height, auto, config)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m# Note, we always `close_app()` here rather than just calling\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39m# `session.open()` if a session already exists, because the app may have\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39m# @todo this can probably be improved\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m    195\u001b[0m close_app()\n\u001b[1;32m--> 197\u001b[0m _session \u001b[39m=\u001b[39m Session(\n\u001b[0;32m    198\u001b[0m     dataset\u001b[39m=\u001b[39;49mdataset,\n\u001b[0;32m    199\u001b[0m     view\u001b[39m=\u001b[39;49mview,\n\u001b[0;32m    200\u001b[0m     spaces\u001b[39m=\u001b[39;49mspaces,\n\u001b[0;32m    201\u001b[0m     color_scheme\u001b[39m=\u001b[39;49mcolor_scheme,\n\u001b[0;32m    202\u001b[0m     plots\u001b[39m=\u001b[39;49mplots,\n\u001b[0;32m    203\u001b[0m     port\u001b[39m=\u001b[39;49mport,\n\u001b[0;32m    204\u001b[0m     address\u001b[39m=\u001b[39;49maddress,\n\u001b[0;32m    205\u001b[0m     remote\u001b[39m=\u001b[39;49mremote,\n\u001b[0;32m    206\u001b[0m     desktop\u001b[39m=\u001b[39;49mdesktop,\n\u001b[0;32m    207\u001b[0m     height\u001b[39m=\u001b[39;49mheight,\n\u001b[0;32m    208\u001b[0m     auto\u001b[39m=\u001b[39;49mauto,\n\u001b[0;32m    209\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    210\u001b[0m )\n\u001b[0;32m    212\u001b[0m \u001b[39mif\u001b[39;00m _session\u001b[39m.\u001b[39mremote:\n\u001b[0;32m    213\u001b[0m     logger\u001b[39m.\u001b[39minfo(_REMOTE_INSTRUCTIONS\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mformat(_session\u001b[39m.\u001b[39mserver_port))\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\fiftyone\\core\\session\\session.py:430\u001b[0m, in \u001b[0;36mSession.__init__\u001b[1;34m(self, dataset, view, view_name, spaces, color_scheme, plots, port, address, remote, desktop, height, auto, config)\u001b[0m\n\u001b[0;32m    427\u001b[0m _register_session(\u001b[39mself\u001b[39m)\n\u001b[0;32m    429\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto \u001b[39mand\u001b[39;00m focx\u001b[39m.\u001b[39mis_notebook_context():\n\u001b[1;32m--> 430\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow(height\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnotebook_height)\n\u001b[0;32m    432\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremote:\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m focx\u001b[39m.\u001b[39mis_notebook_context():\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\fiftyone\\core\\session\\session.py:256\u001b[0m, in \u001b[0;36mupdate_state.<locals>.decorator.<locals>.wrapper\u001b[1;34m(session, *args, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39mif\u001b[39;00m auto_show \u001b[39mand\u001b[39;00m session\u001b[39m.\u001b[39mauto \u001b[39mand\u001b[39;00m focx\u001b[39m.\u001b[39mis_notebook_context():\n\u001b[0;32m    255\u001b[0m     session\u001b[39m.\u001b[39mfreeze()\n\u001b[1;32m--> 256\u001b[0m result \u001b[39m=\u001b[39m func(session, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    257\u001b[0m session\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39msend_event(StateUpdate(state\u001b[39m=\u001b[39msession\u001b[39m.\u001b[39m_state))\n\u001b[0;32m    258\u001b[0m \u001b[39mif\u001b[39;00m auto_show \u001b[39mand\u001b[39;00m session\u001b[39m.\u001b[39mauto \u001b[39mand\u001b[39;00m focx\u001b[39m.\u001b[39mis_notebook_context():\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\fiftyone\\core\\session\\session.py:1024\u001b[0m, in \u001b[0;36mSession.show\u001b[1;34m(self, height)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m focx\u001b[39m.\u001b[39mis_notebook_context() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdesktop:\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m-> 1024\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfreeze()\n\u001b[0;32m   1025\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1026\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m_reload()\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\fiftyone\\core\\session\\session.py:1125\u001b[0m, in \u001b[0;36mSession.freeze\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mOnly notebook sessions can be frozen\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1123\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m-> 1125\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend_event(DeactivateNotebookCell())\n\u001b[0;32m   1126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplots\u001b[39m.\u001b[39mfreeze()\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\fiftyone\\core\\session\\client.py:145\u001b[0m, in \u001b[0;36mClient.send_event\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connected:\n\u001b[1;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mClient is not connected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_event(event)\n\u001b[0;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch_event(event)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Client is not connected"
     ]
    }
   ],
   "source": [
    "# The dataset is constructed from the Open Images v6 dataset. It will contain 25 samples of images where glasses are detected.\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v6\",\n",
    "    split=\"validation\", \n",
    "    label_types=[\"detections\"],\n",
    "    classes=[\"Glasses\"],\n",
    "    max_samples = 25\n",
    "    )\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ImageNet**\n",
    "This dataset is organised according to the WordNet hierarchy. Each node of the hierarchy contains hundreds and thousands of images. Object detection can be trained with this dataset, but here the dataset is previewed for image classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset to 'C:\\Users\\matth\\fiftyone\\imagenet-sample'\n",
      "Downloading dataset...\n",
      " 100% |████|  762.4Mb/762.4Mb [11.3s elapsed, 0s remaining, 64.0Mb/s]      \n",
      "Extracting dataset...\n",
      "Parsing dataset metadata\n",
      "Found 1000 samples\n",
      "Dataset info written to 'C:\\Users\\matth\\fiftyone\\imagenet-sample\\info.json'\n",
      "Loading 'imagenet-sample'\n",
      " 100% |███████████████| 1000/1000 [955.1ms elapsed, 0s remaining, 1.1K samples/s]       \n",
      "Dataset 'imagenet-sample' created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=83a19c96-6d4b-4d0c-93e8-1d75e67c3ee2\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1988d68bdf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to\n",
      "\n",
      "███████╗██╗███████╗████████╗██╗   ██╗ ██████╗ ███╗   ██╗███████╗\n",
      "██╔════╝██║██╔════╝╚══██╔══╝╚██╗ ██╔╝██╔═══██╗████╗  ██║██╔════╝\n",
      "█████╗  ██║█████╗     ██║    ╚████╔╝ ██║   ██║██╔██╗ ██║█████╗\n",
      "██╔══╝  ██║██╔══╝     ██║     ╚██╔╝  ██║   ██║██║╚██╗██║██╔══╝\n",
      "██║     ██║██║        ██║      ██║   ╚██████╔╝██║ ╚████║███████╗\n",
      "╚═╝     ╚═╝╚═╝        ╚═╝      ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚══════╝ v0.21.6\n",
      "\n",
      "If you're finding FiftyOne helpful, here's how you can get involved:\n",
      "\n",
      "|\n",
      "|  ⭐⭐⭐ Give the project a star on GitHub ⭐⭐⭐\n",
      "|  https://github.com/voxel51/fiftyone\n",
      "|\n",
      "|  🚀🚀🚀 Join the FiftyOne Slack community 🚀🚀🚀\n",
      "|  https://slack.voxel51.com\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The dataset is constructed from the ImageNet dataset. \n",
    "dataset = foz.load_zoo_dataset(\"imagenet-sample\")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **COCO**\n",
    "This is a large-scale dataset for object detection and segmentation. It contains 330k images and 80 object categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is constructed from the COCO 2017 dataset. It will contain 25 samples of images where cats and/or dogs are detected.\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"detections\"],\n",
    "    classes=[\"cat\", \"dog\"],\n",
    "    max_samples=25,\n",
    ")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KITTI**\n",
    "This is a dataset which is used for autonomous driving systems. It contains images of cars and pedestrians from the driver's view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is constructed from the KITTI dataset. Note: it takes approximately 25 minutes to download the images.\n",
    "dataset = foz.load_zoo_dataset(\"kitti\", split=\"train\")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASCAL VOC**\n",
    "This dataset contain around 12k images, where each image contains a set of objects. There are 20 object classes available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is constructed from the PASCAL VOC 2012 dataset.\n",
    "dataset = foz.load_zoo_dataset(\"voc-2012\", split=\"validation\")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image segmentation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Open Images**\n",
    "This dataset from Google contains approximately 9 million images annotated with image-level labels and object bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is constructed from the Open Images v6 dataset. It will contain 25 samples of segmented images.\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v6\",\n",
    "    split=\"train\", \n",
    "    label_types=[\"segmentations\"],\n",
    "    max_samples = 25\n",
    "    )\n",
    "session = fo.launch_app(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f418a02590753b7a1c4ceaff2830d9c98c19de9bf29356c9d5ba509b644e4e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
