{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\matth/.cache\\torch\\hub\\ultralytics_yolov5_master\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['gitpython>=3.1.30', 'setuptools>=65.5.1'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  AutoUpdate skipped (offline)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-9-1 Python-3.9.0 torch-1.11.0+cu113 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, _verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bounding boxes\n",
    "def plot_boxes(results, frame, model):\n",
    "\n",
    "\t# Get labels and co√∂rdinates\n",
    "\tlabels, cord = results\n",
    "\n",
    "\t# Get image shape\n",
    "\tx_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "\n",
    "\t# Loop\n",
    "\tcount = 0\n",
    "\tfor i in range(len(labels)):\n",
    "\n",
    "\t\t# Get coordinates of bounding box\n",
    "\t\trow = cord[i]\n",
    "\n",
    "\t\t# Supress\n",
    "\t\tif row[4] < 0.5: continue\n",
    "\n",
    "\t\t# Get pixel coordinates\n",
    "\t\tx1 = int(row[0]*x_shape)\n",
    "\t\ty1 = int(row[1]*y_shape)\n",
    "\t\tx2 = int(row[2]*x_shape)\n",
    "\t\ty2 = int(row[3]*y_shape)\n",
    "\n",
    "\t\t# Color of bounding box\n",
    "\t\tbgr = (0, 255, 0) \n",
    "\n",
    "\t\t# Get the name of label index\n",
    "\t\tclasses = model.names \n",
    "\n",
    "\t\t# If a person\n",
    "\t\tif int(labels[i]) == 0: count += 1\n",
    "\n",
    "\t\t# Get font for the label\n",
    "\t\tlabel_font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "\t\t# Plot the boxes\n",
    "\t\tcv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2) \n",
    "\n",
    "\t\t# Put a label over box.\n",
    "\t\tcv2.putText(frame, classes[int(labels[i])], (x1, y1), label_font, 0.9, bgr, 2) \n",
    "\n",
    "\t# Count people\n",
    "\tcv2.putText(frame, \"Number of visible visitors: \" + str(count), (int(np.shape(frame)[1]/4), 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\treturn frame\n",
    "\n",
    "# Score frame\n",
    "def score_frame(frame, model):\n",
    "\n",
    "\t# Check device\n",
    "\tdevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\tprint(device)\n",
    "\tmodel.to(device)\n",
    "\n",
    "\t# Convert frame to tensor\n",
    "\tframe = [torch.tensor(frame)]\n",
    "\n",
    "\t# Run through network\n",
    "\tresults = model(frame)\n",
    "\n",
    "\t# Retrieve labels en coordinates\n",
    "\tlabels = results.xyxyn[0][:, -1].numpy()\n",
    "\tcord = results.xyxyn[0][:, :-1].numpy()\n",
    "\n",
    "\treturn labels, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/smiling_person.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/smiling_person.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Reshape image\u001b[39;00m\n\u001b[0;32m      5\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2GRAY)\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\ultralytics\\utils\\patches.py:26\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read an image from a file.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mimdecode(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m, flags)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/smiling_person.jpg'"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "img = cv2.imread('data/smiling_person.jpg')\n",
    "\n",
    "# Reshape image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Score the frame\n",
    "results = score_frame(gray, model) \n",
    "\n",
    "# Plot the boxes\n",
    "image = plot_boxes(results, img, model) \n",
    "\n",
    "# Show result\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}