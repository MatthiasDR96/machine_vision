Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\jupyter_core\utils\__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "C:\Python310\lib\asyncio\base_events.py", line 649, in run_until_complete
    return future.result()
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Predicted label of the sampel image
y_pred = model(x[0])
_, class_pred = torch.max(y_pred, 1)

# The true label
y_true = y

# Print result
print("The model predicts the number to be " + str(class_pred.item()) + " and the real number is " + str(y_true[0].item()))
------------------


[1;31m---------------------------------------------------------------------------[0m
[1;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [1;32mIn[10], line 2[0m
[0;32m      1[0m [38;5;66;03m# Predicted label of the sampel image[39;00m
[1;32m----> 2[0m y_pred [38;5;241m=[39m [43mmodel[49m[43m([49m[43mx[49m[43m[[49m[38;5;241;43m0[39;49m[43m][49m[43m)[49m
[0;32m      3[0m _, class_pred [38;5;241m=[39m torch[38;5;241m.[39mmax(y_pred, [38;5;241m1[39m)
[0;32m      5[0m [38;5;66;03m# The true label[39;00m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1518[0m, in [0;36mModule._wrapped_call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1516[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_compiled_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)  [38;5;66;03m# type: ignore[misc][39;00m
[0;32m   1517[0m [38;5;28;01melse[39;00m:
[1;32m-> 1518[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1527[0m, in [0;36mModule._call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1522[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[0;32m   1523[0m [38;5;66;03m# this function, and just call forward.[39;00m
[0;32m   1524[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_backward_pre_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks
[0;32m   1525[0m         [38;5;129;01mor[39;00m _global_backward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[0;32m   1526[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[1;32m-> 1527[0m     [38;5;28;01mreturn[39;00m forward_call([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[0;32m   1529[0m [38;5;28;01mtry[39;00m:
[0;32m   1530[0m     result [38;5;241m=[39m [38;5;28;01mNone[39;00m

Cell [1;32mIn[5], line 14[0m, in [0;36mNeuralNet.forward[1;34m(self, x)[0m
[0;32m     12[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m,x):
[0;32m     13[0m     x [38;5;241m=[39m x[38;5;241m.[39mview([38;5;241m-[39m[38;5;241m1[39m, [38;5;241m28[39m[38;5;241m*[39m[38;5;241m*[39m[38;5;241m2[39m) [38;5;66;03m# First it flattens the image of 28 by 28 to a vector of 28*28 elements because we have a fully connected layer at the beginning[39;00m
[1;32m---> 14[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mR([38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mlinear1[49m[43m([49m[43mx[49m[43m)[49m) [38;5;66;03m# Passing the vector to the first layer, activating the results, and obtaining the outputs[39;00m
[0;32m     15[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mR([38;5;28mself[39m[38;5;241m.[39mlinear2(x)) [38;5;66;03m# Passing the outputs of the previous layer to the second layer, activating the results, and obtaining the outputs[39;00m
[0;32m     16[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mlinear3(x) [38;5;66;03m# Passing the outputs of the previous layer to the final layer and obtaining the outputs[39;00m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1518[0m, in [0;36mModule._wrapped_call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1516[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_compiled_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)  [38;5;66;03m# type: ignore[misc][39;00m
[0;32m   1517[0m [38;5;28;01melse[39;00m:
[1;32m-> 1518[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1527[0m, in [0;36mModule._call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1522[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[0;32m   1523[0m [38;5;66;03m# this function, and just call forward.[39;00m
[0;32m   1524[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_backward_pre_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks
[0;32m   1525[0m         [38;5;129;01mor[39;00m _global_backward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[0;32m   1526[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[1;32m-> 1527[0m     [38;5;28;01mreturn[39;00m forward_call([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[0;32m   1529[0m [38;5;28;01mtry[39;00m:
[0;32m   1530[0m     result [38;5;241m=[39m [38;5;28;01mNone[39;00m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\linear.py:114[0m, in [0;36mLinear.forward[1;34m(self, input)[0m
[0;32m    113[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, [38;5;28minput[39m: Tensor) [38;5;241m-[39m[38;5;241m>[39m Tensor:
[1;32m--> 114[0m     [38;5;28;01mreturn[39;00m [43mF[49m[38;5;241;43m.[39;49m[43mlinear[49m[43m([49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mweight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias[49m[43m)[49m

[1;31mRuntimeError[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)

