Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\jupyter_core\utils\__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "C:\Python310\lib\asyncio\base_events.py", line 649, in run_until_complete
    return future.result()
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Set the optimizer
optimizer = SGD(model.parameters(), lr=0.001)

# Set the loss function
criterium = nn.CrossEntropyLoss()

# Train for 50 epochs
results = train_model(model, optimizer, criterium, n_epochs=10)
------------------

----- stdout -----
Epoch 1/10
----------
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [1;32mIn[7], line 8[0m
[0;32m      5[0m criterium [38;5;241m=[39m nn[38;5;241m.[39mCrossEntropyLoss()
[0;32m      7[0m [38;5;66;03m# Train for 50 epochs[39;00m
[1;32m----> 8[0m results [38;5;241m=[39m [43mtrain_model[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43moptimizer[49m[43m,[49m[43m [49m[43mcriterium[49m[43m,[49m[43m [49m[43mn_epochs[49m[38;5;241;43m=[39;49m[38;5;241;43m10[39;49m[43m)[49m

Cell [1;32mIn[6], line 39[0m, in [0;36mtrain_model[1;34m(model, optimizer, criterum, n_epochs)[0m
[0;32m     36[0m labels [38;5;241m=[39m labels[38;5;241m.[39mto(device)  
[0;32m     38[0m [38;5;66;03m# Forward pass through the network[39;00m
[1;32m---> 39[0m outputs [38;5;241m=[39m [43mmodel[49m[43m([49m[43minputs[49m[43m)[49m
[0;32m     41[0m [38;5;66;03m# Softmax transforms the output probabilities into one selected class[39;00m
[0;32m     42[0m _, class_pred [38;5;241m=[39m torch[38;5;241m.[39mmax(outputs, [38;5;241m1[39m)

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1518[0m, in [0;36mModule._wrapped_call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1516[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_compiled_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)  [38;5;66;03m# type: ignore[misc][39;00m
[0;32m   1517[0m [38;5;28;01melse[39;00m:
[1;32m-> 1518[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1527[0m, in [0;36mModule._call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1522[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[0;32m   1523[0m [38;5;66;03m# this function, and just call forward.[39;00m
[0;32m   1524[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_backward_pre_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks
[0;32m   1525[0m         [38;5;129;01mor[39;00m _global_backward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[0;32m   1526[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[1;32m-> 1527[0m     [38;5;28;01mreturn[39;00m forward_call([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[0;32m   1529[0m [38;5;28;01mtry[39;00m:
[0;32m   1530[0m     result [38;5;241m=[39m [38;5;28;01mNone[39;00m

Cell [1;32mIn[4], line 25[0m, in [0;36mNeuralNet.forward[1;34m(self, x)[0m
[0;32m     24[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m,x):
[1;32m---> 25[0m     x [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mconv1[49m[43m([49m[43mx[49m[43m)[49m [38;5;66;03m# Passing the input image through the first convolutional layer[39;00m
[0;32m     26[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mconv2(x) [38;5;66;03m# Passing the resulting feature maps through the second convolutional layer[39;00m
[0;32m     27[0m     x [38;5;241m=[39m x[38;5;241m.[39mview(x[38;5;241m.[39msize([38;5;241m0[39m),[38;5;241m-[39m[38;5;241m1[39m) [38;5;66;03m# The output of the last convolutional layer is flattened (batch size, 32x7x7)[39;00m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1518[0m, in [0;36mModule._wrapped_call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1516[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_compiled_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)  [38;5;66;03m# type: ignore[misc][39;00m
[0;32m   1517[0m [38;5;28;01melse[39;00m:
[1;32m-> 1518[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1527[0m, in [0;36mModule._call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1522[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[0;32m   1523[0m [38;5;66;03m# this function, and just call forward.[39;00m
[0;32m   1524[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_backward_pre_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks
[0;32m   1525[0m         [38;5;129;01mor[39;00m _global_backward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[0;32m   1526[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[1;32m-> 1527[0m     [38;5;28;01mreturn[39;00m forward_call([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[0;32m   1529[0m [38;5;28;01mtry[39;00m:
[0;32m   1530[0m     result [38;5;241m=[39m [38;5;28;01mNone[39;00m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\container.py:215[0m, in [0;36mSequential.forward[1;34m(self, input)[0m
[0;32m    213[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, [38;5;28minput[39m):
[0;32m    214[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m:
[1;32m--> 215[0m         [38;5;28minput[39m [38;5;241m=[39m [43mmodule[49m[43m([49m[38;5;28;43minput[39;49m[43m)[49m
[0;32m    216[0m     [38;5;28;01mreturn[39;00m [38;5;28minput[39m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1518[0m, in [0;36mModule._wrapped_call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1516[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_compiled_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)  [38;5;66;03m# type: ignore[misc][39;00m
[0;32m   1517[0m [38;5;28;01melse[39;00m:
[1;32m-> 1518[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1527[0m, in [0;36mModule._call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1522[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[0;32m   1523[0m [38;5;66;03m# this function, and just call forward.[39;00m
[0;32m   1524[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_backward_pre_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks
[0;32m   1525[0m         [38;5;129;01mor[39;00m _global_backward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[0;32m   1526[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[1;32m-> 1527[0m     [38;5;28;01mreturn[39;00m forward_call([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[0;32m   1529[0m [38;5;28;01mtry[39;00m:
[0;32m   1530[0m     result [38;5;241m=[39m [38;5;28;01mNone[39;00m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\conv.py:460[0m, in [0;36mConv2d.forward[1;34m(self, input)[0m
[0;32m    459[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, [38;5;28minput[39m: Tensor) [38;5;241m-[39m[38;5;241m>[39m Tensor:
[1;32m--> 460[0m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_conv_forward[49m[43m([49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mweight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias[49m[43m)[49m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\conv.py:456[0m, in [0;36mConv2d._conv_forward[1;34m(self, input, weight, bias)[0m
[0;32m    452[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mpadding_mode [38;5;241m!=[39m [38;5;124m'[39m[38;5;124mzeros[39m[38;5;124m'[39m:
[0;32m    453[0m     [38;5;28;01mreturn[39;00m F[38;5;241m.[39mconv2d(F[38;5;241m.[39mpad([38;5;28minput[39m, [38;5;28mself[39m[38;5;241m.[39m_reversed_padding_repeated_twice, mode[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mpadding_mode),
[0;32m    454[0m                     weight, bias, [38;5;28mself[39m[38;5;241m.[39mstride,
[0;32m    455[0m                     _pair([38;5;241m0[39m), [38;5;28mself[39m[38;5;241m.[39mdilation, [38;5;28mself[39m[38;5;241m.[39mgroups)
[1;32m--> 456[0m [38;5;28;01mreturn[39;00m [43mF[49m[38;5;241;43m.[39;49m[43mconv2d[49m[43m([49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[43mweight[49m[43m,[49m[43m [49m[43mbias[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mstride[49m[43m,[49m
[0;32m    457[0m [43m                [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mpadding[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mdilation[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mgroups[49m[43m)[49m

[1;31mRuntimeError[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same

