Traceback (most recent call last):
  File "C:\Python310\lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\jupyter_core\utils\__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
  File "C:\Python310\lib\asyncio\base_events.py", line 649, in run_until_complete
    return future.result()
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\matth\AppData\Roaming\Python\Python310\site-packages\nbclient\client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Extract a batch
batch = next(iter(train_loader))

# Extract the images and labels
x, y = batch

# Get the predictions for the whole batch
y_pred = model(x).argmax(axis=1)

# Plot predictions and labels
fig, ax = plt.subplots(2,5,figsize=(10,5))
for i in range(10):
    plt.subplot(2,5,i+1)
    plt.imshow(x[i].permute(1,2,0), cmap='gray')
    plt.title(f'Predicted Digit: {y_pred[i]}')
plt.show()
------------------


[1;31m---------------------------------------------------------------------------[0m
[1;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [1;32mIn[9], line 8[0m
[0;32m      5[0m x, y [38;5;241m=[39m batch
[0;32m      7[0m [38;5;66;03m# Get the predictions for the whole batch[39;00m
[1;32m----> 8[0m y_pred [38;5;241m=[39m [43mmodel[49m[43m([49m[43mx[49m[43m)[49m[38;5;241m.[39margmax(axis[38;5;241m=[39m[38;5;241m1[39m)
[0;32m     10[0m [38;5;66;03m# Plot predictions and labels[39;00m
[0;32m     11[0m fig, ax [38;5;241m=[39m plt[38;5;241m.[39msubplots([38;5;241m2[39m,[38;5;241m5[39m,figsize[38;5;241m=[39m([38;5;241m10[39m,[38;5;241m5[39m))

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1518[0m, in [0;36mModule._wrapped_call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1516[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_compiled_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)  [38;5;66;03m# type: ignore[misc][39;00m
[0;32m   1517[0m [38;5;28;01melse[39;00m:
[1;32m-> 1518[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1527[0m, in [0;36mModule._call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1522[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[0;32m   1523[0m [38;5;66;03m# this function, and just call forward.[39;00m
[0;32m   1524[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_backward_pre_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks
[0;32m   1525[0m         [38;5;129;01mor[39;00m _global_backward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[0;32m   1526[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[1;32m-> 1527[0m     [38;5;28;01mreturn[39;00m forward_call([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[0;32m   1529[0m [38;5;28;01mtry[39;00m:
[0;32m   1530[0m     result [38;5;241m=[39m [38;5;28;01mNone[39;00m

Cell [1;32mIn[4], line 25[0m, in [0;36mNeuralNet.forward[1;34m(self, x)[0m
[0;32m     24[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m,x):
[1;32m---> 25[0m     x [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mconv1[49m[43m([49m[43mx[49m[43m)[49m [38;5;66;03m# Passing the input image through the first convolutional layer[39;00m
[0;32m     26[0m     x [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mconv2(x) [38;5;66;03m# Passing the resulting feature maps through the second convolutional layer[39;00m
[0;32m     27[0m     x [38;5;241m=[39m x[38;5;241m.[39mview(x[38;5;241m.[39msize([38;5;241m0[39m),[38;5;241m-[39m[38;5;241m1[39m) [38;5;66;03m# The output of the last convolutional layer is flattened (batch size, 32x7x7)[39;00m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1518[0m, in [0;36mModule._wrapped_call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1516[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_compiled_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)  [38;5;66;03m# type: ignore[misc][39;00m
[0;32m   1517[0m [38;5;28;01melse[39;00m:
[1;32m-> 1518[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1527[0m, in [0;36mModule._call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1522[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[0;32m   1523[0m [38;5;66;03m# this function, and just call forward.[39;00m
[0;32m   1524[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_backward_pre_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks
[0;32m   1525[0m         [38;5;129;01mor[39;00m _global_backward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[0;32m   1526[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[1;32m-> 1527[0m     [38;5;28;01mreturn[39;00m forward_call([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[0;32m   1529[0m [38;5;28;01mtry[39;00m:
[0;32m   1530[0m     result [38;5;241m=[39m [38;5;28;01mNone[39;00m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\container.py:215[0m, in [0;36mSequential.forward[1;34m(self, input)[0m
[0;32m    213[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, [38;5;28minput[39m):
[0;32m    214[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m:
[1;32m--> 215[0m         [38;5;28minput[39m [38;5;241m=[39m [43mmodule[49m[43m([49m[38;5;28;43minput[39;49m[43m)[49m
[0;32m    216[0m     [38;5;28;01mreturn[39;00m [38;5;28minput[39m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1518[0m, in [0;36mModule._wrapped_call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1516[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_compiled_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)  [38;5;66;03m# type: ignore[misc][39;00m
[0;32m   1517[0m [38;5;28;01melse[39;00m:
[1;32m-> 1518[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\module.py:1527[0m, in [0;36mModule._call_impl[1;34m(self, *args, **kwargs)[0m
[0;32m   1522[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
[0;32m   1523[0m [38;5;66;03m# this function, and just call forward.[39;00m
[0;32m   1524[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_backward_pre_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks
[0;32m   1525[0m         [38;5;129;01mor[39;00m _global_backward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
[0;32m   1526[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
[1;32m-> 1527[0m     [38;5;28;01mreturn[39;00m forward_call([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[0;32m   1529[0m [38;5;28;01mtry[39;00m:
[0;32m   1530[0m     result [38;5;241m=[39m [38;5;28;01mNone[39;00m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\conv.py:460[0m, in [0;36mConv2d.forward[1;34m(self, input)[0m
[0;32m    459[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, [38;5;28minput[39m: Tensor) [38;5;241m-[39m[38;5;241m>[39m Tensor:
[1;32m--> 460[0m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_conv_forward[49m[43m([49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mweight[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbias[49m[43m)[49m

File [1;32mC:\Python310\lib\site-packages\torch\nn\modules\conv.py:456[0m, in [0;36mConv2d._conv_forward[1;34m(self, input, weight, bias)[0m
[0;32m    452[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mpadding_mode [38;5;241m!=[39m [38;5;124m'[39m[38;5;124mzeros[39m[38;5;124m'[39m:
[0;32m    453[0m     [38;5;28;01mreturn[39;00m F[38;5;241m.[39mconv2d(F[38;5;241m.[39mpad([38;5;28minput[39m, [38;5;28mself[39m[38;5;241m.[39m_reversed_padding_repeated_twice, mode[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mpadding_mode),
[0;32m    454[0m                     weight, bias, [38;5;28mself[39m[38;5;241m.[39mstride,
[0;32m    455[0m                     _pair([38;5;241m0[39m), [38;5;28mself[39m[38;5;241m.[39mdilation, [38;5;28mself[39m[38;5;241m.[39mgroups)
[1;32m--> 456[0m [38;5;28;01mreturn[39;00m [43mF[49m[38;5;241;43m.[39;49m[43mconv2d[49m[43m([49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[43mweight[49m[43m,[49m[43m [49m[43mbias[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mstride[49m[43m,[49m
[0;32m    457[0m [43m                [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mpadding[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mdilation[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mgroups[49m[43m)[49m

[1;31mRuntimeError[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor

