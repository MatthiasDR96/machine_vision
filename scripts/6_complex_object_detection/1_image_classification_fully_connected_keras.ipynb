{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using fully connected layers with Keras\n",
    "In this notebook, a Neural Network using fully connected layers will be build from scratch and trained on the MNIST dataset. The MNIST dataset is a dataset containing hand-written images of digits. The end goal is to label the images with their corresponding digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "First, the MNIST data is loaded from the Keras dataset library. It directly loads in a training and test dataset. X denotes the images and y denotes the labels. We can also have a look at the size of these datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset contains 60000 samples.\n",
      "The test dataset contains 10000 samples.\n"
     ]
    }
   ],
   "source": [
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Print results\n",
    "print('The train dataset contains ' + str(x_train.shape[0]) + ' samples.')\n",
    "print('The test dataset contains ' + str(x_test.shape[0]) + ' samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the images are converted to doubles and normalized. Initially, the images have pixel values ranging from 0 to 255 (8 bits). But for the network to train faster, it is always beneficial to normalize the input values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels of the dataset are numbers from 0 to 9. It is common practice in neural network training to convert these numbers to binary vectors  with a 1 at the index of the correct number and zeros everywhere else. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of the first image is: 5\n",
      "The new label of the first image is: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# The labels of the dataset are the correct numbers for each image\n",
    "print(\"The label of the first image is: \" + str(y_train[0]))\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# The labels are converted to binary vectors\n",
    "print(\"The new label of the first image is: \" + str(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the neural network model\n",
    "As a neural network, we use a two fully connected (dense) layers. The first layer outputs 128 neurons and has a ReLu activation layer. The second layer outputs 10 neurons that each represent a class instance, being a number from 0 to 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {"tags": [
    "scroll-output"
    ]},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101770 (397.54 KB)\n",
      "Trainable params: 101770 (397.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defines the neural network model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(10)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Summarizes the model and its parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "Before we can train the model, we need to define what loss, optimizer, and accuracy metric we want to use. As we are dealing with a multi-class classification problem, we use the categorical cross entropy loss. As optimizer we use the popular Adam algorithm. And we will define accuracy as the metric of goodness for our network. We also define that we will validate the network after every epoch on a dataset that has 10% of the samples in the training dataset that was defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {"tags": [
    "scroll-output"
    ]},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - 3s 5ms/step - loss: 9.1000 - accuracy: 0.1630 - val_loss: 9.5988 - val_accuracy: 0.1542\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 10.2861 - accuracy: 0.1171 - val_loss: 11.3445 - val_accuracy: 0.0997\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 9.9307 - accuracy: 0.1180 - val_loss: 8.8166 - val_accuracy: 0.1132\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 9.6216 - accuracy: 0.1118 - val_loss: 9.7461 - val_accuracy: 0.1120\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 10.3320 - accuracy: 0.1112 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 10.4033 - accuracy: 0.1111 - val_loss: 10.1356 - val_accuracy: 0.1115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14f8cf3cca0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "\n",
    "# Define the loss function, optimizer, and accuracy metric\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation\n",
    "When the model is trained, we can evalueate its performance on the test set. By calling the evaluate-function of the model it uses the earlier defined goodness metric for the evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 10.35588264465332\n",
      "Test accuracy: 0.10849999636411667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print results\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
